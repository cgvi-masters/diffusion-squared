{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb82576",
   "metadata": {},
   "source": [
    "## Simple UNet\n",
    "\n",
    "Simple UNet for generating shadow images given random blob and lightsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings  # suppress warning from gen seg image\n",
    "warnings.filterwarnings(\"ignore\", message=\"The balance properties of Sobol' points require n to be a power of 2.\")\n",
    "\n",
    "# import functions from src code\n",
    "from real_src.utils import set_device, get_num_workers\n",
    "from real_src.architecture_unet import UNet\n",
    "from real_src.database_toy import LightSourceDB, sample_batch_toy, generate_img_pair\n",
    "from real_src.unet_train_test import train_unet, test_unet, load_model, plot_MAE_per_angle\n",
    "\n",
    "# reflect changes in src code immediately without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eebd9",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_device()\n",
    "num_workers = get_num_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264c3ab",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d83d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and move to device\n",
    "model = UNet(in_chan=1, out_chan=1, cond_dim=2)\n",
    "model.to(device)\n",
    "\n",
    "# define hyperparameters for optimization\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "\n",
    "# optimizer (Adam seemed to work better than SGD)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb6381",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "\n",
    "# partition data  (if choosing angles ensure between -pi to pi in rads)\n",
    "#train_set = LightSourceDB(num_samples=2000, method=\"constrained\", min_angle = -np.pi, max_angle = np.pi/2) \n",
    "#train_set = LightSourceDB(num_samples=num_samples, method=\"constrained\", min_angle = -np.pi, max_angle = np.pi - np.pi/36) \n",
    "#val_set = LightSourceDB(num_samples=100, method=\"constrained\", min_angle = -np.pi, max_angle = np.pi - np.pi/36)\n",
    "train_set = LightSourceDB(num_samples=num_samples, method=\"random\")\n",
    "val_set = LightSourceDB(num_samples=num_samples, method=\"random\")\n",
    "\n",
    "# create dataloaders for easy iteration\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size)\n",
    "\n",
    "# display sample from batch to verify data\n",
    "sample_batch_toy(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7fb83",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439febd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model, saves weights in model folder, and plots loss curve\n",
    "train_unet(model, device, train_loader, val_loader, loss_fn, optimizer, \n",
    "            epochs, batch_size, learning_rate, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36bca7",
   "metadata": {},
   "source": [
    "### Load and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9eb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_dim = 2\n",
    "model_path = \"models/unet_23.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb221282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot title\n",
    "super_title = \"Constrained Pos from -pi to 0 Degrees with 2,000 Samples (Inverted) and 1 FiLM Layer at Bottleneck\"\n",
    "\n",
    "# test set\n",
    "test_set = LightSourceDB(num_samples=5, method=\"fixed\", fixed_angle=-0.030543262) \n",
    "# [-1.8325957, -0.030543262, 0.0, 0.06544985, 0.10035643, 0.1308997, 0.13526301, 0.16580628, 0.19634955, 0.2617994, \n",
    "# 0.29670596, 0.36651915, 1.2740904, 1.3089969, 2.8405232, 2.8448868, 2.8754299, 2.8797932\n",
    "\n",
    "# test model on 5 random unseen samples\n",
    "test_unet(loaded_model, test_set, device, super_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa33b9c",
   "metadata": {},
   "source": [
    "### Evaluate Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19eaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "cond_dim = 2\n",
    "model_path = \"models/unet_23.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1487d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params and plot\n",
    "num_angles = 360\n",
    "samples_per_angle = 1\n",
    "\n",
    "plot_MAE_per_angle(num_angles, samples_per_angle, loaded_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe16b5e",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- way to visualize model with nodes etc  - torchviz\n",
    "  - torchviz, torchview, and netron are all pretty bad with unet\n",
    "  -  some other good models for pretty graphs for papers, but have to do more manually\n",
    "  - https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network \n",
    "- no callbacks at the end of epochs in pytorch, only keras\n",
    "- stopping criteria, save model along the way\n",
    "- have output show input/output/gt for 5 images (5x3 plot)\n",
    "- error coming from gen seg - added try catch so model can continue\n",
    "- store models locally not on git (just weights not whole model)\n",
    "- have validation set in train loop and then test set at the end\n",
    "- save hyperparameters as well (batch size, epochs etc for each model in a dict)\n",
    "- inverted images so that background values are 0 and not 1\n",
    "  - now when padding with zeros (default) it doesnt create strange artifacts on edges\n",
    "- added momentum term to SGD\n",
    "- created different modes of generating pos (fixed, 4 corners, and random all directions)\n",
    "- encoded light source param as film layer\n",
    "- refactored organization into src code file\n",
    "- way to work with src code where i dont have to refresh kernel each time -> autoreload\n",
    "- pass angle as condition (just a scalar theta) instead of x,y coords\n",
    "  - however, when its trained on a range (ex -pi to 0) it does not understand periodicity that -pi=pi\n",
    "  - this creates a discontinuity, thus the error increases in a spiral as it goes up from 0 to pi\n",
    "  - instead we can pass values as sin(theta), cos(theta) which outputs the 2d coords on the unit circle\n",
    "  - for example, not pi and -pi will map to the same point [-1,0]\n",
    "- plot how well model performs for each angle - plot MAE (not MSE)\n",
    "\n",
    "## To do\n",
    "- verify dimensions of last convolution of upsampling\n",
    "- make the model creation more modular with inputs as lists of channels [16, 32, ...] [512, ]\n",
    "- tensorboard visualization during training process\n",
    "  - cool to visualize data at lower dimension (3D) like PCA\n",
    "- different loss functions (ADAM)\n",
    "- also try encorporating the film layer at more points than just the bottleneck\n",
    "- figure out how to have model running while computer closed\n",
    "  - or just connect to UCL remote GPU\n",
    "  - or just use local machines\n",
    "- print all intermediate stages to see whats going on behind the hood\n",
    "- try with different radii (probably just need more training examples)\n",
    "\n",
    "- keep one fixed sample, and pass it through each epoch to see how it learns, make into GIF\n",
    "- generate unseen angles, train on 3/4 of circle and test on unseen 1/4, how well it interpolates (>5 degree angle)\n",
    "- maybe try for more epochs and less data?\n",
    "  - or create a dataset beforehand instead of generating on fly\n",
    "\n",
    "- quaternions - help to avoid the discontinuity for angles in 3d\n",
    "\n",
    "- train a model on random positions, then when testing mae, mask out everyhting but a circle in the center\n",
    "- to get rid of the artifacts that come from the corners that give it a starlike shape\n",
    "\n",
    "- try and create a dataloader for the nifty real images\n",
    "  - just the brain, the skull etc has been masked out\n",
    "  - dataset takes in list of files, and then dataloader randomly grabs a slice from one of the files\n",
    "  - needs to normalize intensities as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f04c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target, source = generate_img_pair(np.array([64,64]), np.pi, 31)\n",
    "mask = img != 0\n",
    "print(mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
