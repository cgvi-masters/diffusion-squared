{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9839bb70",
   "metadata": {},
   "source": [
    "## Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3acf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import custom src code\n",
    "from real_src.utils import get_num_workers, set_device, load_model\n",
    "from real_src.architecture_unet import UNet\n",
    "from real_src.database_mri import MRImagesDB, sample_batch_mri\n",
    "\n",
    "# import other src code\n",
    "from src_diffusion.testing import sample\n",
    "#from src_diffusion.training import train_diffusion_model\n",
    "\n",
    "# reflect changes in src code immediately without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ef8cc",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e10cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device depending on available GPU\n",
    "device = set_device()\n",
    "num_workers = get_num_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665900a2",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the conditioning dimension\n",
    "# 3 for toy data:   1 for timestep, 2 for angle (x, y) on unit circle\n",
    "# 8 for MRI data:   1 for timestep, 1 for scalar bval, and 6 for transformed bvec \n",
    "cond_dim = 8       \n",
    "\n",
    "# 2 channels for shape image + noised img (shadow/dwi)\n",
    "in_chan = 2\n",
    "\n",
    "# create model and move to device\n",
    "model = UNet(in_chan=in_chan, cond_dim=cond_dim)\n",
    "model.to(device)\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "epochs = 3000\n",
    "\n",
    "# optimizer (Adam seemed to work better than SGD)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# choose axis to slice along: 0 = saggital, 1 = coronal, 2 = horizontal\n",
    "slice_axis = 2\n",
    "\n",
    "# diffusion hyperparameters (from DDPM paper)\n",
    "timesteps = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd51ae5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1867bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file paths\n",
    "data_dir_path = '../DWsynth_project/'                #'/cs/student/projects3/cgvi/2024/morrison/DWsynth_project/'\n",
    "bvals_path = data_dir_path + 'bvals_round.bval'\n",
    "bvecs_path = data_dir_path + 'bvecs.bvec'\n",
    "img_dir_path = data_dir_path + 'train'\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = [1, 96, 96, 70]\n",
    "\n",
    "# number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# create dataset and dataloader\n",
    "train_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=slice_axis)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, num_workers=num_workers,\n",
    "                          pin_memory=torch.cuda.is_available(),  persistent_workers=torch.cuda.is_available()) # speeds up GPU transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample from batch to verify data\n",
    "sample_batch_mri(DataLoader(dataset=train_set, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ad1fc",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fbe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model, saves weights in model folder, and plots loss curve\n",
    "train_diffusion_model(model, device, train_set, train_loader, loss_fn, optimizer,\n",
    "            epochs, batch_size, learning_rate, timesteps, beta_start, beta_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d4059",
   "metadata": {},
   "source": [
    "### Load and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set unet dims\n",
    "cond_dim = 8        # 1 for timestep, 3 for bvec, 1 for bval\n",
    "in_chan = 2         # change to 2 channels for noisy shadow img + blob image       \n",
    "\n",
    "model_path = \"models_diffusion/best_diffusion_model.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim, in_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to test dataset\n",
    "data_dir_path = '../DWsynth_project/'\n",
    "bvals_path = data_dir_path + 'bvals_round.bval'\n",
    "bvecs_path = data_dir_path + 'bvecs.bvec'\n",
    "img_dir_path = data_dir_path + 'test'\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = [1, 96, 96, 70]\n",
    "\n",
    "# sample from diffusion model\n",
    "n_samples = 10\n",
    "\n",
    "# noise scheduler\n",
    "timesteps = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02\n",
    "\n",
    "# image shape\n",
    "img_shape = [1, 96, 96]    # [C, H, W] for MRI data\n",
    "\n",
    "# choose axis to slice along: 0 = saggital, 1 = coronal, 2 = horizontal\n",
    "slice_axis = 2\n",
    "\n",
    "# create test data\n",
    "test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=n_samples, slice_axis=slice_axis)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd86cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first test DDPM sampling \n",
    "sampler = 'ddpm'\n",
    "samples, gt_shadows, blobs = sample(loaded_model, test_loader, n_samples, timesteps, beta_start, beta_end, img_shape, device, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(anat, gt, preds):\n",
    "    \"\"\"\n",
    "    anat, gt, preds: tensors of shape [b, 1, 96, 96]\n",
    "    \"\"\"\n",
    "    b = anat.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(b, 3, figsize=(9, 3*b))\n",
    "\n",
    "    if b == 1:  # special case if batch size = 1\n",
    "        axes = axes[None, :]  # add batch dim\n",
    "\n",
    "    # set column titles only for the first row\n",
    "    col_titles = [\"Anatomical\", \"Ground Truth\", \"Prediction\"]\n",
    "    for j, title in enumerate(col_titles):\n",
    "        axes[0, j].set_title(title)\n",
    "\n",
    "    for i in range(b):\n",
    "        # anatomical image\n",
    "        axes[i, 0].imshow(anat[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        # ground truth\n",
    "        axes[i, 1].imshow(gt[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        # prediction\n",
    "        axes[i, 2].imshow(preds[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\", vmin=0, vmax=1)\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(blobs, gt_shadows, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then try DDIM sampling, (faster and more efficient)\n",
    "ddim_steps = 100 \n",
    "ddim_eta = 0.0  # usually set to 0.0 for deterministic sampling\n",
    "\n",
    "ddim_samples = sample(loaded_model, test_loader, n_samples, timesteps, beta_start, beta_end, img_shape, device, sampler='ddpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdef8bf",
   "metadata": {},
   "source": [
    "## Make GIFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_src.utils import create_rotation_gif_frames, set_device, load_model\n",
    "\n",
    "method = 'diffusion'\n",
    "subject = 'sub-012-01'\n",
    "slice_idx = 32\n",
    "\n",
    "save_dir = 'bvec_rotation_diffusion'\n",
    "\n",
    "data_dir_path = '../DWsynth_project/'\n",
    "\n",
    "model_path = 'models_diffusion/best_diffusion_model.pth'\n",
    "cond_dim = 8\n",
    "in_chan = 2\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "loaded_model = load_model(model_path, device, cond_dim=cond_dim, in_chan=in_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6298164",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rotation_gif_frames(method, subject, slice_idx, data_dir_path, save_dir, loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_src.utils import create_rotation_gif\n",
    "\n",
    "gif_name = \"diffusion_rotation_gif_with_anat.gif\"\n",
    "create_rotation_gif(save_dir, gif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a55802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945da2b4",
   "metadata": {},
   "source": [
    "## SLICE STACK\n",
    "\n",
    "first generate a random DWI volume, and ideally pick one with 2000 bval for better contrast\n",
    "Then create the full stack of slices from this volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e994bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_random_dwi_vol(bvals_path, bvecs_path):\n",
    "    \n",
    "    bvals = np.loadtxt(bvals_path)\n",
    "    bvecs = np.loadtxt(bvecs_path)\n",
    "\n",
    "    dw_inds = np.where(bvals > 0)[0]\n",
    "    b0_inds = np.where(bvals == 0)[0]\n",
    "\n",
    "    vol_ind = dw_inds[np.random.randint(0, len(dw_inds))]\n",
    "    b0_ind = b0_inds[np.random.randint(0, len(b0_inds))]\n",
    "\n",
    "    bvec = bvecs[:, vol_ind]\n",
    "    bval = bvals[vol_ind]\n",
    "\n",
    "    print(\"bvalue:\", bval)\n",
    "\n",
    "    return vol_ind, b0_ind, bvec, bval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths \n",
    "img_dir_path = data_dir_path + 'test'\n",
    "bvals_path = data_dir_path + 'bvals_round.bval'\n",
    "bvecs_path = data_dir_path + 'bvecs.bvec'\n",
    "\n",
    "# generate until we get desired bval\n",
    "vol_ind, b0_ind, bvec, bval = generate_random_dwi_vol(bvals_path, bvecs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FOR LATENT MODELS #####\n",
    "\n",
    "# load encoder blob and decoder shadow\n",
    "from src_latent.autoencoder import load_ae\n",
    "\n",
    "from src_latent.testing import sample_latent\n",
    "\n",
    "shadow_ae = load_ae(\"models_diffusion/ae_dw.pth\", device)\n",
    "blob_ae = load_ae(\"models_diffusion/ae_anat.pth\", device)\n",
    "\n",
    "# extract encoder and decoder components\n",
    "encoder_shadow = shadow_ae.encoder\n",
    "decoder_shadow = shadow_ae.decoder\n",
    "encoder_blob = blob_ae.encoder\n",
    "\n",
    "# move all to device\n",
    "encoder_shadow = encoder_shadow.to(device)\n",
    "decoder_shadow = decoder_shadow.to(device)\n",
    "encoder_blob = encoder_blob.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dffc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for slice consistency experiment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src_unet.testing import test_unet\n",
    "import os\n",
    "import torchio as tio\n",
    "\n",
    "# set unet dims\n",
    "cond_dim = 7        # 8 for diffusion, 7 for unet\n",
    "in_chan = 1         # 2 for diffuion, 1 for unet    \n",
    "\n",
    "# set unet dims for LATENT\n",
    "#latent_chan = 8\n",
    "#in_chan = 2 * latent_chan # multiplied by the latent dim\n",
    "#out_chan = latent_chan  # out_chan should be same as latent_chan, then we use decoder to get back to original chan\n",
    "#cond_dim = 8\n",
    "\n",
    "# load model\n",
    "model_path = \"models_diffusion/best_unet_model.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim, in_chan)\n",
    "\n",
    "# choose method of model to generate slices\n",
    "method = 'unet'\n",
    "\n",
    "# choose a subject\n",
    "subject = 'sub-030-01'\n",
    "\n",
    "# needed for diffusion for some reason even though we only need one sample\n",
    "num_samples = 3\n",
    "\n",
    "# get the ground truth image\n",
    "anat_path = os.path.join(img_dir_path, subject, 'anat', subject + '_t1.nii.gz')\n",
    "dw_path = os.path.join(img_dir_path, subject, 'dwi', subject + '_dwi_preproc_' + str(vol_ind) + '.nii.gz')\n",
    "b0_path = os.path.join(img_dir_path, subject, 'dwi', subject + '_dwi_preproc_' + str(b0_ind) + '.nii.gz')\n",
    "\n",
    "anat_vol = tio.ScalarImage(anat_path).data.numpy() \n",
    "dw_vol = tio.ScalarImage(dw_path).data.numpy()\n",
    "b0_vol = tio.ScalarImage(b0_path).data.numpy()\n",
    "\n",
    "dw_vol_norm = np.clip(dw_vol / (b0_vol + 1e-10), 0, 1)  # normalize by b0 volume\n",
    "mask = anat_vol > 0\n",
    "dw_vol_norm = dw_vol_norm * mask\n",
    "dw_vol_norm = dw_vol_norm[0]   # [96, 96, 70]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all horizontal slices\n",
    "dw_hat = np.zeros((0,96,96))\n",
    "\n",
    "for slice_idx in range(70):\n",
    "\n",
    "    test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=2, \n",
    "                        subject=subject, slice_idx=slice_idx, bval=bval, bvec=bvec)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=num_samples)\n",
    "    \n",
    "    # determine method: diffusion, latent diffusion, or unet\n",
    "    if method == \"diffusion\":\n",
    "        sampler = 'ddpm'\n",
    "        timesteps = 1000\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        img_shape = volume_dims[:3]\n",
    "        \n",
    "        #betas, alphas, alphas_bar = get_noise_scheduler('linear', timesteps, beta_start, beta_end, device)\n",
    "        ddpm_sample, gt_shadows, blobs = sample(loaded_model, test_loader, num_samples, timesteps, beta_start, beta_end, img_shape, device, sampler=sampler)\n",
    "        yhat = ddpm_sample.detach().cpu().numpy()[0]  #[1, 96, 96] takes the first sample of 3\n",
    "        print(slice_idx)\n",
    "    \n",
    "    elif method == \"unet\":\n",
    "            inputs, targets, preds = test_unet(loaded_model, test_set, device)\n",
    "            yhat = preds[0]\n",
    "            yhat = yhat[None, ...] # add dimension so [1,96,96]\n",
    "\n",
    "    elif method == \"latent\":\n",
    "        sampler = 'ddpm'\n",
    "        timesteps = 1000\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        \n",
    "        ddpm_sample, gt_shadows = sample_latent(loaded_model, test_loader, num_samples, timesteps, beta_start, beta_end, device, sampler, \n",
    "                                                encoder_blob, decoder_shadow)\n",
    "        yhat = ddpm_sample.detach().cpu().numpy()[0]      #[1, 96, 96] takes the first sample of 3\n",
    "        print(slice_idx)\n",
    "\n",
    "    dw_hat = np.concatenate((dw_hat, yhat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))   # make the figure bigger (adjust size as needed)\n",
    "plt.imshow((np.rot90(dw_vol_norm[:,:,34], k=1)), cmap=\"gray\", vmin=0, vmax=1)  # rotate 90 degrees for correct orientation\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))   # make the figure bigger (adjust size as needed)\n",
    "plt.imshow((np.rot90(dw_hat[34,:,:], k=1)), cmap=\"gray\", vmin=0, vmax=1)  # rotate 90 degrees for correct orientation\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ac717",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('slice_stack_DDPM_DIFF_NOW', dw_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just show slices from anat for figure\n",
    "print(anat_vol.shape)\n",
    "sagittal = np.rot90(anat_vol[0,40,:,:], k=3)\n",
    "coronal = np.flipud(np.rot90(anat_vol[0,:,43,:], k=1))\n",
    "axial = np.flipud(np.rot90(anat_vol[0,:,:,36], k=1))\n",
    "\n",
    "plt.figure(figsize=(6,6))   # make the figure bigger (adjust size as needed)\n",
    "plt.imshow(axial, origin='lower', cmap='gray')\n",
    "plt.axis('off')             # turns off axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice from actual dw volume\n",
    "\n",
    "sagittal_target = np.fliplr(np.rot90(dw_vol_norm[40,:,:], k=1))\n",
    "coronal_target = np.rot90(dw_vol_norm[:,43,:], k=1)\n",
    "\n",
    "plt.figure()  \n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sagittal, vmin=0, vmax=1)\n",
    "plt.axis('off')   \n",
    "plt.title(\"Sagittal\")   \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(coronal, vmin=0, vmax=1)\n",
    "plt.axis('off')    \n",
    "plt.title(\"Coronal\")  \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(sagittal, vmin=0, vmax=1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(coronal, vmin=0, vmax=1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack created by model then sliced in other directions\n",
    "\n",
    "plt.figure()   \n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.fliplr(dw_hat[:,40,:]), origin='lower', vmin=0, vmax=1)\n",
    "plt.axis('off')  \n",
    "plt.title(\"Sagittal\")  \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dw_hat[:,:,43], origin='lower', vmin=0, vmax=1)\n",
    "plt.axis('off')    \n",
    "plt.title(\"Coronal\") \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sagittal_pred = np.fliplr(dw_hat[:,40,:])\n",
    "coronal_pred = dw_hat[:,:,43]\n",
    "\n",
    "plt.imshow(np.fliplr(dw_hat[:,40,:]), vmin=0, vmax=1, cmap='gray', origin='lower')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(dw_hat[:,:,43], vmin=0, vmax=1, cmap='gray', origin='lower')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9df011",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('slice_stack_latent_ddpm', dw_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('slice_stack_diff.npy')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "data_range = sagittal_target.max() - sagittal_target.min()\n",
    "\n",
    "# predictions\n",
    "sagittal_pred = np.flipud(np.fliplr(dw_hat[:,40,:]))\n",
    "coronal_pred = np.flipud(dw_hat[:,:,43])\n",
    "\n",
    "# compute ssim\n",
    "ssim_val = ssim(sagittal_pred, sagittal_target, data_range=data_range)\n",
    "psnr_val = psnr(sagittal_pred, sagittal_target, data_range=data_range)\n",
    "print(\"Sagittal slice:\")\n",
    "print(\"SSIM:\", ssim_val)\n",
    "print(\"PSNR:\", psnr_val)\n",
    "\n",
    "# compute ssim\n",
    "ssim_val = ssim(coronal_pred, coronal_target, data_range=data_range)\n",
    "psnr_val = psnr(coronal_pred, coronal_target, data_range=data_range)\n",
    "print(\"Coronal slice:\")\n",
    "print(\"SSIM:\", ssim_val)\n",
    "print(\"PSNR:\", psnr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for slice consistency experiment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src_unet.testing import test_model\n",
    "import os\n",
    "import torchio as tio\n",
    "\n",
    "# set unet dims\n",
    "cond_dim = 7        # 8 for diffusion bc of timestep\n",
    "in_chan = 1         # change to 2 channels for noisy img + shape image       \n",
    "\n",
    "# load model\n",
    "model_path = \"models_diffusion/best_unet_model.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim, in_chan)\n",
    "\n",
    "# choose a subject\n",
    "subject = 'sub-012-01'\n",
    "\n",
    "# get the ground truth image\n",
    "anat_path = os.path.join(img_dir_path, subject, 'anat', subject + '_t1.nii.gz')\n",
    "dw_path = os.path.join(img_dir_path, subject, 'dwi', subject + '_dwi_preproc_' + str(vol_ind) + '.nii.gz')\n",
    "b0_path = os.path.join(img_dir_path, subject, 'dwi', subject + '_dwi_preproc_' + str(b0_ind) + '.nii.gz')\n",
    "\n",
    "anat_vol = tio.ScalarImage(anat_path).data.numpy() \n",
    "dw_vol = tio.ScalarImage(dw_path).data.numpy()\n",
    "b0_vol = tio.ScalarImage(b0_path).data.numpy()\n",
    "\n",
    "dw_vol_norm = np.clip(dw_vol / (b0_vol + 1e-10), 0, 1)  # normalize by b0 volume\n",
    "mask = anat_vol > 0\n",
    "dw_vol_norm = dw_vol_norm * mask\n",
    "dw_vol_norm = dw_vol_norm[0]   # [96, 96, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose method of model to generate slices\n",
    "method = 'unet'\n",
    "\n",
    "# needed for diffusion for some reason even though we only need one sample\n",
    "num_samples = 3\n",
    "\n",
    "# iterate through all horizontal slices\n",
    "dw_hat2 = np.zeros((0,96,96))\n",
    "\n",
    "for slice_idx in range(70):\n",
    "\n",
    "    test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=2, \n",
    "                        subject=subject, slice_idx=slice_idx, bval=bval, bvec=bvec)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=num_samples)\n",
    "    \n",
    "    # determine method: diffusion, latent diffusion, or unet\n",
    "    if method == \"diffusion\":\n",
    "        sampler = 'ddim'\n",
    "        timesteps = 1000\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        img_shape = volume_dims[:3]\n",
    "        \n",
    "        #betas, alphas, alphas_bar = get_noise_scheduler('linear', timesteps, beta_start, beta_end, device)\n",
    "        ddpm_sample = sample(loaded_model, test_loader, num_samples, timesteps, beta_start, beta_end, img_shape, device, sampler=sampler)\n",
    "        yhat = ddpm_sample.detach().cpu().numpy()[0]  #[1, 96, 96] takes the first sample of 3\n",
    "    \n",
    "    elif method == \"unet\":\n",
    "            inputs, targets, preds = test_model(loaded_model, test_set, device)\n",
    "            yhat = preds[0]\n",
    "            yhat = yhat[None, ...] # add dimension so [1,96,96]\n",
    "\n",
    "    dw_hat2 = np.concatenate((dw_hat2, yhat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32953f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet stack \n",
    "plt.figure()   \n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.fliplr(dw_hat2[:,40,:]), origin='lower', vmin=0, vmax=1)\n",
    "plt.axis('off')  \n",
    "plt.title(\"Sagittal\")  \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dw_hat2[:,:,43], origin='lower', vmin=0, vmax=1)\n",
    "plt.axis('off')    \n",
    "plt.title(\"Coronal\") \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f04a61",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Test each of the three models by taking one slice from each volume for each patient in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader with specific bval/bvec/slice/subject\n",
    "            \n",
    "\n",
    "# slice axis set = 2 as these models were only trained on horizontal slices\n",
    "\n",
    "slice_idx = 3\n",
    "\n",
    "\n",
    "\n",
    "test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=2, \n",
    "                        subject=subject, slice_idx=slice_idx, bval=bval, bvec=bvec)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2159396d",
   "metadata": {},
   "source": [
    "### SSIM / PSNR\n",
    "\n",
    "The model generates samples way too slow one by one, need to work on getting batching to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aef7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idx variable in __getitem__ is directly related to the batch size - its the index in the list\n",
    "# so if batch_size = 10 it would go from 0-9\n",
    "\n",
    "# we need a way to use this for the generation task\n",
    "# set the batch size to 118 so that it aligns with the number of volumes for each subject\n",
    "# use that instead of the volume index variable??\n",
    "\n",
    "# wait theres 118 total (but 13 B0 volumes) so really only 105 dw volumes we need to compute metrics for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed63e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set unet dims\n",
    "cond_dim = 8        # 1 for timestep, 6 for bvec, 1 for bval\n",
    "in_chan = 2         # change to 2 channels for noisy img + shape image       \n",
    "\n",
    "model_path = \"models_diffusion/best_diffusion_model.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim, in_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75868643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "data_dir_path = '../DWsynth_project/'\n",
    "img_dir_path = os.path.join(data_dir_path, 'test')\n",
    "bvals_path = os.path.join(data_dir_path, 'bvals_round.bval')\n",
    "bvecs_path = os.path.join(data_dir_path, 'bvecs.bvec')\n",
    "\n",
    "# load bvals and bvecs\n",
    "bvals = np.loadtxt(bvals_path)\n",
    "bvecs = np.loadtxt(bvecs_path)\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = [1, 96, 96, 70]\n",
    "\n",
    "# choose method of generating images\n",
    "method = 'diffusion'\n",
    "\n",
    "# list of 50 test subjects\n",
    "subjects = next(os.walk(img_dir_path))[1]\n",
    "\n",
    "# indices where bvals non zero (dw)\n",
    "dw_inds = np.where(bvals > 0)[0]\n",
    "\n",
    "# total number of dw volumes for each subject (118)\n",
    "#num_volumes = len(bvals)\n",
    "\n",
    "# num samples (number of non-zero dw volumes = 105)\n",
    "num_samples = len(dw_inds)\n",
    "\n",
    "# decide slice index (maybe middle slice)\n",
    "slice_idx = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_metrics(preds, targets):\n",
    "    \n",
    "    ssim_vals, psnr_vals = [], []\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        pred = preds[i].astype(np.float64)\n",
    "        target = targets[i].astype(np.float64)\n",
    "\n",
    "        data_range = target.max() - target.min()\n",
    "        \n",
    "        # compute ssim\n",
    "        ssim_val = ssim(pred, target, data_range=data_range)\n",
    "        ssim_vals.append(ssim_val)\n",
    "\n",
    "        # compute psnr\n",
    "        psnr_val = psnr(pred, target, data_range=data_range)\n",
    "        psnr_vals.append(psnr_val)\n",
    "\n",
    "    return ssim_vals, psnr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dce30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create pandas df\n",
    "ssim_results_list = []\n",
    "psnr_results_list = []\n",
    "\n",
    "ctr = 0\n",
    "\n",
    "# iterate through each subject\n",
    "for subject in subjects:\n",
    "\n",
    "    # create dataloader - just needs subject and slice idx\n",
    "    test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=2, \n",
    "                              subject=subject, slice_idx=slice_idx)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=num_samples)\n",
    "\n",
    "    if method == \"diffusion\":\n",
    "        sampler = 'ddpm'\n",
    "        timesteps = 1000\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        img_shape = volume_dims[:3]\n",
    "        \n",
    "        ddpm_sample, gt_shadows = sample(loaded_model, test_loader, num_samples, timesteps, beta_start, beta_end, img_shape, device, sampler=sampler)\n",
    "        \n",
    "        preds = ddpm_sample.detach().cpu().numpy()[:,0,:,:]     # get rid of channel dim so just [B, 96, 96]\n",
    "        targets = gt_shadows.detach().cpu().numpy()[:,0,:,:]\n",
    "\n",
    "    ctr += 1\n",
    "    print(ctr)\n",
    "\n",
    "    # get ssim and psnr esults for the batch (subject) and add to master list\n",
    "    ssim_results, psnr_results = batch_metrics(preds, targets)\n",
    "    ssim_results_list.append(ssim_results)\n",
    "    psnr_results_list.append(psnr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "# match bvals  (105 non zero bvals in order)\n",
    "matched_bvals = [bvals[i] for i in dw_inds]\n",
    "\n",
    "for subj in range(50):\n",
    "\n",
    "    # store as df\n",
    "    df = pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"bval\": matched_bvals,\n",
    "        \"ssim\": ssim_results_list[subj],\n",
    "        \"psnr\": psnr_results_list[subj]\n",
    "    })\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# concatenate all subjects into one big dataframe\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# mean SSIM and PSNR per bval across all subjects\n",
    "mean_metrics = df_all.groupby(\"bval\")[[\"ssim\", \"psnr\"]].mean()\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATAFRAME!!!\n",
    "\n",
    "df_all.to_csv(\"diffusion_metrics_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = pd.read_csv(\"diffusion_metrics_df.csv\")\n",
    "mean_metrics = loaded_df.groupby(\"bval\")[[\"ssim\", \"psnr\"]].mean()\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d11ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 750 of bval=650, 1500 of bval=1000, 3000 of bval=2000 -> 5250 samples total\n",
    "\n",
    "# SSIM ranges from [-1, 1] -> values closer to 1 are better (perfect reconstruction), .85 is good similarity but small diff like noise etc\n",
    "# PSNR higher values mean better quality, > 40 is excellent, 20-30 is acceptable but noticable differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot for SSIM\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=\"bval\", y=\"ssim\", data=loaded_df, palette=\"Set2\", showfliers=False)\n",
    "#sns.stripplot(x=\"bval\", y=\"SSIM\", data=df, color=\"black\", size=3, alpha=0.5)  # overlay points\n",
    "plt.title(\"SSIM distribution per b-value\")\n",
    "plt.xlabel(\"b-value\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "#plt.ylim(0.75, 1)  # since SSIM âˆˆ [0,1]\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for PSNR\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=\"bval\", y=\"psnr\", data=loaded_df, palette=\"Set2\", showfliers=False)\n",
    "plt.title(\"PSNR distribution per b-value\")\n",
    "plt.xlabel(\"b-value\")\n",
    "plt.ylabel(\"PSNR (dB)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
