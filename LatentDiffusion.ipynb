{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4771a9",
   "metadata": {},
   "source": [
    "## Latent Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# library for loading and manipulating medical images\n",
    "import torchio as tio\n",
    "\n",
    "# import custom src code\n",
    "from src_latent.architecture import UNet\n",
    "from src_latent.autoencoder import AutoEncoder, VAE, train_ae, train_vae, load_ae, test_model\n",
    "from src_latent.database_toy import LightSourceDB, sample_batch_toy\n",
    "from src_latent.testing import sample_latent, load_unet\n",
    "from src_latent.training import train_model, get_noise_scheduler\n",
    "\n",
    "# reflect changes in src code immediately without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d540ef",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71855018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device depending on available GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps:0\")  # use mac GPU if available (first mps index in case multiple)\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4cfce",
   "metadata": {},
   "source": [
    "### Create and Train Autoencoders\n",
    "Train autoencoders for input and target data separately. Later use input encoder and target decoder for LDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent dimension of embeddings produced by encoder\n",
    "latent_chan = 8\n",
    "\n",
    "# create model and move to device\n",
    "model = AutoEncoder(latent_chan=latent_chan)\n",
    "model.to(device)\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "\n",
    "# optimizer (Adam seems to perform better than SGD)\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04298d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically set number of workers to optimize use of cores\n",
    "def get_num_workers():\n",
    "    try:\n",
    "        num_cpus = os.cpu_count()\n",
    "        # heuristic: leave 1â€“2 cores free\n",
    "        workers = max(1, num_cpus - 2)\n",
    "        return workers\n",
    "    except:\n",
    "        return 4  # fallback default\n",
    "\n",
    "num_workers = get_num_workers()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# create dataset and dataloader\n",
    "train_set = LightSourceDB(num_samples=2048, method=\"random\") \n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, \n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=torch.cuda.is_available(),  # speeds up GPU transfer\n",
    "                            persistent_workers=True)\n",
    "\n",
    "# sanity check: print first batch of data\n",
    "sample_batch_toy(train_loader)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fd97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom src code\n",
    "from src_diffusion.architecture import UNet\n",
    "from src_diffusion.database import MRImagesDB\n",
    "from src_diffusion.training import sample_batch, train_model, get_noise_scheduler\n",
    "from src_diffusion.testing import load_model, sample\n",
    "\n",
    "# load files\n",
    "data_dir_path = '/cs/student/projects3/cgvi/2024/morrison/DWsynth_project/'\n",
    "bvals_path = data_dir_path + 'bvals_round.bval'\n",
    "bvecs_path = data_dir_path + 'bvecs.bvec'\n",
    "img_dir_path = data_dir_path + 'train'\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = tio.ScalarImage(data_dir_path + 'train/sub-051-01/anat/sub-051-01_t1.nii.gz').data.shape\n",
    "\n",
    "# choose axis to slice along: 0 = saggital, 1 = coronal, 2 = horizontal\n",
    "slice_axis = 2\n",
    "\n",
    "\n",
    "# create dataset and dataloader\n",
    "train_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=1000, slice_axis=slice_axis)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=torch.cuda.is_available(),  # speeds up GPU transfer\n",
    "                            persistent_workers=True)\n",
    "\n",
    "# display sample from batch to verify data\n",
    "sample_batch(DataLoader(dataset=train_set, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data type (blob or shadow)\n",
    "data_type=\"blob\"\n",
    "\n",
    "# train the model, saves weights in model folder, and plots loss curve\n",
    "train_ae(model, device, train_loader, loss_fn, optimizer, epochs, batch_size, learning_rate, data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48767ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so above we have started training an autoencoder for the blobs which is the anatomical images\n",
    "# now we will train an autoencoder for the shadow/ diffusion images \n",
    "# then we can use these for latent diffusion on the real data\n",
    "\n",
    "\n",
    "# latent dimension of embeddings produced by encoder\n",
    "latent_chan = 8\n",
    "\n",
    "# create model and move to device\n",
    "model = AutoEncoder(latent_chan=latent_chan)\n",
    "model.to(device)\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "\n",
    "# optimizer (Adam seems to perform better than SGD)\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "num_workers = get_num_workers()\n",
    "\n",
    "# create dataset and dataloader\n",
    "train_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=2048, slice_axis=slice_axis)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=torch.cuda.is_available(),  # speeds up GPU transfer\n",
    "                            persistent_workers=True)\n",
    "\n",
    "# display sample from batch to verify data\n",
    "sample_batch(DataLoader(dataset=train_set, batch_size=batch_size))\n",
    "\n",
    "# select data type (blob or shadow)\n",
    "data_type=\"shadow\"\n",
    "\n",
    "# train the model, saves weights in model folder, and plots loss curve\n",
    "train_ae(model, device, train_loader, loss_fn, optimizer, epochs, batch_size, learning_rate, data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added parameters to testing function\n",
    "\n",
    "num_samples = 5\n",
    "data_type = \"shadow\"\n",
    "model_path = \"models_diffusion/ae_dw.pth\"\n",
    "\n",
    "loaded_model = load_ae(model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ef62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on 5 random unseen samples\n",
    "inputs, preds = test_model(loaded_model, device, num_samples, num_workers, super_title=\"\", data_type=data_type)\n",
    "print(inputs[0].max(), preds[0].max())\n",
    "print(inputs[0].min(), preds[0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac3877",
   "metadata": {},
   "source": [
    "### Separate the Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee62ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the encoder from the blob autoencoder\n",
    "encoder = loaded_model.encoder\n",
    "encoder.to(device)\n",
    "\n",
    "# sample a batch of blobs from training loader\n",
    "test_set = LightSourceDB(num_samples=5, method=\"random\") \n",
    "test_loader = DataLoader(dataset=test_set, batch_size=5)\n",
    "sample_blobs = next(iter(test_loader))[0]\n",
    "\n",
    "# input blob images and get latent rep\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    latent_blobs = encoder(sample_blobs.to(device))\n",
    "\n",
    "# convert to numpy for plotting\n",
    "sample_blobs = sample_blobs.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "# test putting the latent codes back into the decoder\n",
    "decoder = loaded_model.decoder\n",
    "decoder.to(device)\n",
    "\n",
    "# reconstruct the blobs from the latent codes\n",
    "decoder.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed_blobs = decoder(latent_blobs)\n",
    "\n",
    "# convert to numpy for plotting\n",
    "reconstructed_blobs = reconstructed_blobs.detach().squeeze().cpu().numpy()\n",
    "\n",
    "# display\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original images in the first row\n",
    "    axes[0, i].imshow(sample_blobs[i])\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Ground Truth')\n",
    "\n",
    "    # Plot reconstructed images in the second row\n",
    "    axes[1, i].imshow(reconstructed_blobs[i])\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Reconstructed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febeede",
   "metadata": {},
   "source": [
    "### Lets try latent diffusion\n",
    "- encorporate the encoder and decoder into the training code\n",
    "- then just set up diffusion as normal??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff437e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device depending on available GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps:0\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoencoders for shadow and blob\n",
    "shadow_ae = load_ae(\"models_diffusion/ae_dw.pth\", device)\n",
    "blob_ae = load_ae(\"models_diffusion/ae_anat.pth\", device)\n",
    "\n",
    "# extract encoder and decoder components\n",
    "encoder_shadow = shadow_ae.encoder\n",
    "decoder_shadow = shadow_ae.decoder\n",
    "encoder_blob = blob_ae.encoder\n",
    "\n",
    "# move all to device\n",
    "encoder_shadow = encoder_shadow.to(device)\n",
    "decoder_shadow = decoder_shadow.to(device)\n",
    "encoder_blob = encoder_blob.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd03664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the conditioning dimension\n",
    "# 3 for toy data:   1 for timestep, 2 for angle (x, y) on unit circle\n",
    "# 5 for MRI data:   1 for timestep, 3 for (x,y,z) bvec and 1 for scalar bval\n",
    "# 8 for better MRI: 1 for timestep, 6 for transformed bvec and 1 for scalar bval\n",
    "cond_dim = 8     \n",
    "\n",
    "# change to 2 channels for shape image + noisy output img (shadow/dwi)\n",
    "# now going to be 2 multiplied by the latent dim\n",
    "latent_chan = 8\n",
    "in_chan = 2 * latent_chan\n",
    "out_chan = latent_chan  # out_chan should be same as latent_chan, then we use decoder to get back to original chan\n",
    "\n",
    "# create model and move to device\n",
    "model = UNet(in_chan=in_chan, out_chan=out_chan, cond_dim=cond_dim)\n",
    "model.to(device)\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "epochs = 3000\n",
    "\n",
    "# optimizer (Adam seemed to work better than SGD)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# choose axis to slice along: 0 = saggital, 1 = coronal, 2 = horizontal\n",
    "slice_axis = 2\n",
    "\n",
    "# diffusion hyperparameters (from DDPM paper)\n",
    "timesteps = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or test model on toy data\n",
    "#train_set = LightSourceDB(num_samples=1000, method=\"random\") \n",
    "#train_loader = DataLoader(dataset=train_set, batch_size=batch_size)\n",
    "\n",
    "# display sample from batch to verify data\n",
    "#sample_batch_toy(DataLoader(dataset=train_set, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "data_dir_path = '../DWsynth_project/'\n",
    "bvals_path = data_dir_path + 'bvals_round.bval'\n",
    "bvecs_path = data_dir_path + 'bvecs.bvec'\n",
    "img_dir_path = data_dir_path + 'train'\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = tio.ScalarImage(data_dir_path + 'train/sub-051-01/anat/sub-051-01_t1.nii.gz').data.shape\n",
    "\n",
    "# choose axis to slice along: 0 = saggital, 1 = coronal, 2 = horizontal\n",
    "slice_axis = 2\n",
    "\n",
    "\n",
    "# create dataset and dataloader\n",
    "train_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=1000, slice_axis=slice_axis)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=torch.cuda.is_available(),  # speeds up GPU transfer\n",
    "                            persistent_workers=torch.cuda.is_available())\n",
    "\n",
    "# display sample from batch to verify data\n",
    "sample_batch(DataLoader(dataset=train_set, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide signal type for training\n",
    "data_type = 'shadows'             # 'blobs' or 'shadows'\n",
    "\n",
    "# train model, saves weights in model folder, and plots loss curve\n",
    "train_model(model, device, train_set, train_loader, loss_fn, optimizer,\n",
    "            epochs, batch_size, learning_rate, timesteps, beta_start, beta_end, data_type, encoder_shadow, encoder_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same unet dims as above\n",
    "model_path = \"models_diffusion/best_latent_diffusion_model.pth\"\n",
    "loaded_model = load_unet(model_path, device, in_chan, out_chan, cond_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceeaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = next(iter(DataLoader(dataset=LightSourceDB(num_samples=1, method=\"random\"), batch_size=1)))[0][0].shape\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from diffusion model\n",
    "n_samples = 5\n",
    "\n",
    "# noise scheduler\n",
    "timesteps = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02\n",
    "betas, alphas, alphas_bar = get_noise_scheduler('linear', timesteps, beta_start, beta_end, device)\n",
    "\n",
    "# image shape\n",
    "img_shape = volume_dims[:3]    # (C, H, W). for MRI data\n",
    "#img_shape = next(iter(DataLoader(dataset=LightSourceDB(num_samples=1, method=\"random\"), batch_size=1)))[0][0].shape    #(C, H, W)\n",
    "\n",
    "# create test data\n",
    "#test_loader = DataLoader(dataset=LightSourceDB(num_samples=n_samples, method=\"random\"), batch_size=n_samples)\n",
    "img_dir_path = data_dir_path + 'test'\n",
    "test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=n_samples, slice_axis=slice_axis)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler='ddpm'\n",
    "#ddpm_samples = sample(loaded_model, test_loader, n_samples, timesteps, betas, alphas, alphas_bar, device, sampler, \n",
    "#                      encoder_blob, decoder_shadow)\n",
    "\n",
    "decoded_samples, gt_shadows, blobs = sample_latent(loaded_model, test_loader, n_samples, timesteps, beta_start, beta_end, device,\n",
    "           sampler, encoder_blob, decoder_shadow, ddim_steps=None, ddim_eta=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed285f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(anat, gt, preds):\n",
    "    \"\"\"\n",
    "    anat, gt, preds: tensors of shape [b, 1, 96, 96]\n",
    "    \"\"\"\n",
    "    b = anat.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(b, 3, figsize=(9, 3*b))\n",
    "\n",
    "    if b == 1:  # special case if batch size = 1\n",
    "        axes = axes[None, :]  # add batch dim\n",
    "\n",
    "    # set column titles only for the first row\n",
    "    col_titles = [\"Anatomical\", \"Ground Truth\", \"Prediction\"]\n",
    "    for j, title in enumerate(col_titles):\n",
    "        axes[0, j].set_title(title)\n",
    "\n",
    "    for i in range(b):\n",
    "        # anatomical image\n",
    "        axes[i, 0].imshow(anat[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        # ground truth\n",
    "        axes[i, 1].imshow(gt[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        # prediction\n",
    "        axes[i, 2].imshow(preds[i, 0].detach().cpu().numpy(), cmap=\"gray\", origin=\"lower\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(decoded_samples, gt_shadows, blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09bb7a",
   "metadata": {},
   "source": [
    "### SSIM and PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ef8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from real_src.utils import load_model, get_num_workers, set_device, batch_metrics\n",
    "from src_latent.testing import sample_latent\n",
    "from real_src.database_mri import MRImagesDB\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc86d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device depending on available GPU\n",
    "device = set_device()\n",
    "num_workers = get_num_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fbe267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set unet dims\n",
    "cond_dim = 8        # 1 for timestep, 6 for bvec, 1 for bval\n",
    "in_chan = 2         # change to 2 channels for noisy img + shape image   \n",
    "latent_chan = 8\n",
    "in_chan = 2 * latent_chan # multiplied by the latent dim\n",
    "out_chan = latent_chan  # out_chan should be same as latent_chan, then we use decoder to get back to original chan\n",
    "\n",
    "model_path = \"models_diffusion/best_latent_diffusion_model.pth\"\n",
    "loaded_model = load_model(model_path, device, cond_dim, in_chan, out_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoder blob and decoder shadow\n",
    "from src_latent.autoencoder import load_ae\n",
    "\n",
    "shadow_ae = load_ae(\"models_diffusion/ae_dw.pth\", device)\n",
    "blob_ae = load_ae(\"models_diffusion/ae_anat.pth\", device)\n",
    "\n",
    "# extract encoder and decoder components\n",
    "encoder_shadow = shadow_ae.encoder\n",
    "decoder_shadow = shadow_ae.decoder\n",
    "encoder_blob = blob_ae.encoder\n",
    "\n",
    "# move all to device\n",
    "encoder_shadow = encoder_shadow.to(device)\n",
    "decoder_shadow = decoder_shadow.to(device)\n",
    "encoder_blob = encoder_blob.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "data_dir_path = '../DWsynth_project/'\n",
    "img_dir_path = os.path.join(data_dir_path, 'test')\n",
    "bvals_path = os.path.join(data_dir_path, 'bvals_round.bval')\n",
    "bvecs_path = os.path.join(data_dir_path, 'bvecs.bvec')\n",
    "\n",
    "# load bvals and bvecs\n",
    "bvals = np.loadtxt(bvals_path)\n",
    "bvecs = np.loadtxt(bvecs_path)\n",
    "\n",
    "# volume dimensions  [1, H, W, D]\n",
    "volume_dims = [1, 96, 96, 70]\n",
    "\n",
    "# choose method of generating images\n",
    "method = 'latent'\n",
    "\n",
    "# list of 50 test subjects\n",
    "subjects = next(os.walk(img_dir_path))[1]\n",
    "\n",
    "# indices where bvals non zero (dw)\n",
    "dw_inds = np.where(bvals > 0)[0]\n",
    "\n",
    "# num samples (number of non-zero dw volumes = 105 out of 118 total volumes)\n",
    "num_samples = len(dw_inds)\n",
    "\n",
    "# decide slice index (maybe middle slice)\n",
    "slice_idx = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create pandas df\n",
    "ssim_results_list = []\n",
    "psnr_results_list = []\n",
    "\n",
    "ctr = 0\n",
    "\n",
    "# iterate through each subject\n",
    "for subject in subjects:\n",
    "\n",
    "    # create dataloader - just needs subject and slice idx\n",
    "    test_set = MRImagesDB(img_dir_path, bvals_path, bvecs_path, volume_dims, num_samples=num_samples, slice_axis=2, \n",
    "                              subject=subject, slice_idx=slice_idx)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=num_samples)\n",
    "\n",
    "    if method == \"latent\":\n",
    "        sampler = 'ddpm'\n",
    "        timesteps = 1000\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        \n",
    "        ###\n",
    "        ddpm_sample, gt_shadows = sample_latent(loaded_model, test_loader, num_samples, timesteps, beta_start, beta_end, device, sampler, \n",
    "                                                encoder_blob, decoder_shadow)\n",
    "        \n",
    "        preds = ddpm_sample.detach().cpu().numpy()[:,0,:,:]     # get rid of channel dim so just [B, 96, 96]\n",
    "        targets = gt_shadows.detach().cpu().numpy()[:,0,:,:]\n",
    "\n",
    "    ctr += 1\n",
    "    print(ctr)\n",
    "\n",
    "    # get ssim and psnr esults for the batch (subject) and add to master list\n",
    "    ssim_results, psnr_results = batch_metrics(preds, targets)\n",
    "    ssim_results_list.append(ssim_results)\n",
    "    psnr_results_list.append(psnr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "# match bvals  (105 non zero bvals in order)\n",
    "matched_bvals = [bvals[i] for i in dw_inds]\n",
    "\n",
    "for subj in range(50):\n",
    "\n",
    "    # store as df\n",
    "    df = pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"bval\": matched_bvals,\n",
    "        \"ssim\": ssim_results_list[subj],\n",
    "        \"psnr\": psnr_results_list[subj]\n",
    "    })\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# concatenate all subjects into one big dataframe\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# mean SSIM and PSNR per bval across all subjects\n",
    "mean_metrics = df_all.groupby(\"bval\")[[\"ssim\", \"psnr\"]].mean()\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATAFRAME!!!\n",
    "\n",
    "df_all.to_csv(\"metrics_df_latent.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
